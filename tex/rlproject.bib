@article{fedavg,
  title    = {Communication-{Efficient} {Learning} of {Deep} {Networks} from {Decentralized} {Data}},
  url      = {http://arxiv.org/abs/1602.05629},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
  urldate  = {2022-01-19},
  journal  = {arXiv:1602.05629 [cs]},
  author   = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Agüera y},
  month    = feb,
  year     = {2017},
  note     = {arXiv: 1602.05629},
  keywords = {Computer Science - Machine Learning},
  annote   = {Comment: This version updates the large-scale LSTM experiments, along with other minor changes. In earlier versions, an inconsistency in our implementation of FedSGD caused us to report much lower learning rates for the large-scale LSTM. We reran these experiments, and also found that fewer local epochs offers better performance, leading to slightly better results for FedAvg than previously reported},
  file     = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/5Z5KBYAE/McMahan et al. - 2017 - Communication-Efficient Learning of Deep Networks .pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/WBR8F5AS/1602.html:text/html}
}

@article{lai_oort_2021,
  title      = {Oort: {Efficient} {Federated} {Learning} via {Guided} {Participant} {Selection}},
  shorttitle = {Oort},
  url        = {http://arxiv.org/abs/2010.06081},
  abstract   = {Federated Learning (FL) is an emerging direction in distributed machine learning (ML) that enables in-situ model training and testing on edge data. Despite having the same end goals as traditional ML, FL executions differ significantly in scale, spanning thousands to millions of participating devices. As a result, data characteristics and device capabilities vary widely across clients. Yet, existing efforts randomly select FL participants, which leads to poor model and system efficiency. In this paper, we propose Oort to improve the performance of federated training and testing with guided participant selection. With an aim to improve time-to-accuracy performance in model training, Oort prioritizes the use of those clients who have both data that offers the greatest utility in improving model accuracy and the capability to run training quickly. To enable FL developers to interpret their results in model testing, Oort enforces their requirements on the distribution of participant data while improving the duration of federated testing by cherry-picking clients. Our evaluation shows that, compared to existing participant selection mechanisms, Oort improves time-to-accuracy performance by 1.2x-14.1x and final model accuracy by 1.3\%-9.8\%, while efficiently enforcing developer-specified model testing criteria at the scale of millions of clients.},
  urldate    = {2022-01-26},
  journal    = {arXiv:2010.06081 [cs]},
  author     = {Lai, Fan and Zhu, Xiangfeng and Madhyastha, Harsha V. and Chowdhury, Mosharaf},
  month      = may,
  year       = {2021},
  note       = {arXiv: 2010.06081},
  keywords   = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
  file       = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/HIP9UIUZ/Lai et al. - 2021 - Oort Efficient Federated Learning via Guided Part.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/S5P7T9B3/2010.html:text/html}
}

@misc{alphastarblog,
  title        = {{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}},
  author       = {Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojtek and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
  howpublished = {\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
  year         = {2019}
}

@techreport{openai_dota_2019,
  title       = {Dota 2 with {Large} {Scale} {Deep} {Reinforcement} {Learning}},
  url         = {http://arxiv.org/abs/1912.06680},
  abstract    = {On April 13th, 2019, OpenAI Five became the first AI system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG), OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.},
  number      = {arXiv:1912.06680},
  urldate     = {2022-06-07},
  institution = {arXiv},
  author      = {OpenAI and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
  month       = dec,
  year        = {2019},
  doi         = {10.48550/arXiv.1912.06680},
  note        = {arXiv:1912.06680 [cs, stat]
                 type: article},
  keywords    = {Computer Science - Machine Learning, Statistics - Machine Learning},
  file        = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/9DKBD69Q/OpenAI et al. - 2019 - Dota 2 with Large Scale Deep Reinforcement Learnin.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/UUQIIP3A/1912.html:text/html}
}

@article{silver_mastering_2016,
  title    = {Mastering the game of {Go} with deep neural networks and tree search},
  volume   = {529},
  issn     = {0028-0836, 1476-4687},
  url      = {http://www.nature.com/articles/nature16961},
  doi      = {10.1038/nature16961},
  language = {en},
  number   = {7587},
  urldate  = {2022-06-07},
  journal  = {Nature},
  author   = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  month    = jan,
  year     = {2016},
  pages    = {484--489},
  file     = {Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:/home/mjhukig/Zotero/storage/7EBWVB6V/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:application/pdf}
}

@techreport{qi_federated_2021,
  title       = {Federated {Reinforcement} {Learning}: {Techniques}, {Applications}, and {Open} {Challenges}},
  shorttitle  = {Federated {Reinforcement} {Learning}},
  url         = {http://arxiv.org/abs/2108.11887},
  abstract    = {This paper presents a comprehensive survey of Federated Reinforcement Learning (FRL), an emerging and promising field in Reinforcement Learning (RL). Starting with a tutorial of Federated Learning (FL) and RL, we then focus on the introduction of FRL as a new method with great potential by leveraging the basic idea of FL to improve the performance of RL while preserving data-privacy. According to the distribution characteristics of the agents in the framework, FRL algorithms can be divided into two categories, i.e. Horizontal Federated Reinforcement Learning (HFRL) and Vertical Federated Reinforcement Learning (VFRL). We provide the detailed definitions of each category by formulas, investigate the evolution of FRL from a technical perspective, and highlight its advantages over previous RL algorithms. In addition, the existing works on FRL are summarized by application fields, including edge computing, communication, control optimization, and attack detection. Finally, we describe and discuss several key research directions that are crucial to solving the open problems within FRL.},
  number      = {arXiv:2108.11887},
  urldate     = {2022-06-07},
  institution = {arXiv},
  author      = {Qi, Jiaju and Zhou, Qihao and Lei, Lei and Zheng, Kan},
  month       = oct,
  year        = {2021},
  doi         = {10.48550/arXiv.2108.11887},
  note        = {arXiv:2108.11887 [cs]
                 type: article},
  keywords    = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  file        = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/54XDGQHH/Qi et al. - 2021 - Federated Reinforcement Learning Techniques, Appl.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/7EMGR9ZW/2108.html:text/html}
}

@misc{noauthor_openaigym_2022,
  title     = {openai/gym},
  url       = {https://github.com/openai/gym},
  abstract  = {A toolkit for developing and comparing reinforcement learning algorithms.},
  urldate   = {2022-06-07},
  publisher = {OpenAI},
  month     = jun,
  year      = {2022},
  note      = {original-date: 2016-04-27T14:59:16Z}
}

@techreport{bellver_hierarchical_2016,
  title       = {Hierarchical {Object} {Detection} with {Deep} {Reinforcement} {Learning}},
  url         = {http://arxiv.org/abs/1611.03718},
  abstract    = {We present a method for performing hierarchical object detection in images guided by a deep reinforcement learning agent. The key idea is to focus on those parts of the image that contain richer information and zoom on them. We train an intelligent agent that, given an image window, is capable of deciding where to focus the attention among five different predefined region candidates (smaller windows). This procedure is iterated providing a hierarchical image analysis.We compare two different candidate proposal strategies to guide the object search: with and without overlap. Moreover, our work compares two different strategies to extract features from a convolutional neural network for each region proposal: a first one that computes new feature maps for each region proposal, and a second one that computes the feature maps for the whole image to later generate crops for each region proposal. Experiments indicate better results for the overlapping candidate proposal strategy and a loss of performance for the cropped image features due to the loss of spatial resolution. We argue that, while this loss seems unavoidable when working with large amounts of object candidates, the much more reduced amount of region proposals generated by our reinforcement learning agent allows considering to extract features for each location without sharing convolutional computation among regions.},
  number      = {arXiv:1611.03718},
  urldate     = {2022-06-07},
  institution = {arXiv},
  author      = {Bellver, Miriam and Giro-i-Nieto, Xavier and Marques, Ferran and Torres, Jordi},
  month       = nov,
  year        = {2016},
  doi         = {10.48550/arXiv.1611.03718},
  note        = {arXiv:1611.03718 [cs]
                 type: article},
  keywords    = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  annote      = {Comment: Deep Reinforcement Learning Workshop (NIPS 2016). Project page at https://imatge-upc.github.io/detection-2016-nipsws/},
  file        = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/SNKJD9FT/Bellver et al. - 2016 - Hierarchical Object Detection with Deep Reinforcem.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/8LUVVDS4/1611.html:text/html}
}

@inproceedings{siddique_unsupervised_2020,
  title     = {Unsupervised {Paraphrasing} via {Deep} {Reinforcement} {Learning}},
  url       = {http://arxiv.org/abs/2007.02244},
  doi       = {10.1145/3394486.3403231},
  abstract  = {Paraphrasing is expressing the meaning of an input sentence in different wording while maintaining fluency (i.e., grammatical and syntactical correctness). Most existing work on paraphrasing use supervised models that are limited to specific domains (e.g., image captions). Such models can neither be straightforwardly transferred to other domains nor generalize well, and creating labeled training data for new domains is expensive and laborious. The need for paraphrasing across different domains and the scarcity of labeled training data in many such domains call for exploring unsupervised paraphrase generation methods. We propose Progressive Unsupervised Paraphrasing (PUP): a novel unsupervised paraphrase generation method based on deep reinforcement learning (DRL). PUP uses a variational autoencoder (trained using a non-parallel corpus) to generate a seed paraphrase that warm-starts the DRL model. Then, PUP progressively tunes the seed paraphrase guided by our novel reward function which combines semantic adequacy, language fluency, and expression diversity measures to quantify the quality of the generated paraphrases in each iteration without needing parallel sentences. Our extensive experimental evaluation shows that PUP outperforms unsupervised state-of-the-art paraphrasing techniques in terms of both automatic metrics and user studies on four real datasets. We also show that PUP outperforms domain-adapted supervised algorithms on several datasets. Our evaluation also shows that PUP achieves a great trade-off between semantic similarity and diversity of expression.},
  urldate   = {2022-06-07},
  booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
  author    = {Siddique, A. B. and Oymak, Samet and Hristidis, Vagelis},
  month     = aug,
  year      = {2020},
  note      = {arXiv:2007.02244 [cs]},
  keywords  = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  pages     = {1800--1809},
  file      = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/6JRTVCF2/Siddique et al. - 2020 - Unsupervised Paraphrasing via Deep Reinforcement L.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/4BYV7BKW/2007.html:text/html}
}

@techreport{wei_federated_2019,
  title       = {Federated {Learning} with {Differential} {Privacy}: {Algorithms} and {Performance} {Analysis}},
  shorttitle  = {Federated {Learning} with {Differential} {Privacy}},
  url         = {http://arxiv.org/abs/1911.00222},
  abstract    = {In this paper, to effectively prevent information leakage, we propose a novel framework based on the concept of differential privacy (DP), in which artificial noises are added to the parameters at the clients side before aggregating, namely, noising before model aggregation FL (NbAFL). First, we prove that the NbAFL can satisfy DP under distinct protection levels by properly adapting different variances of artificial noises. Then we develop a theoretical convergence bound of the loss function of the trained FL model in the NbAFL. Specifically, the theoretical bound reveals the following three key properties: 1) There is a tradeoff between the convergence performance and privacy protection levels, i.e., a better convergence performance leads to a lower protection level; 2) Given a fixed privacy protection level, increasing the number \$N\$ of overall clients participating in FL can improve the convergence performance; 3) There is an optimal number of maximum aggregation times (communication rounds) in terms of convergence performance for a given protection level. Furthermore, we propose a \$K\$-random scheduling strategy, where \$K\$ (\$1{\textless}K{\textless}N\$) clients are randomly selected from the \$N\$ overall clients to participate in each aggregation. We also develop the corresponding convergence bound of the loss function in this case and the \$K\$-random scheduling strategy can also retain the above three properties. Moreover, we find that there is an optimal \$K\$ that achieves the best convergence performance at a fixed privacy level. Evaluations demonstrate that our theoretical results are consistent with simulations, thereby facilitating the designs on various privacy-preserving FL algorithms with different tradeoff requirements on convergence performance and privacy levels.},
  number      = {arXiv:1911.00222},
  urldate     = {2022-06-07},
  institution = {arXiv},
  author      = {Wei, Kang and Li, Jun and Ding, Ming and Ma, Chuan and Yang, Howard H. and Farhad, Farokhi and Jin, Shi and Quek, Tony Q. S. and Poor, H. Vincent},
  month       = nov,
  year        = {2019},
  doi         = {10.48550/arXiv.1911.00222},
  note        = {arXiv:1911.00222 [cs]
                 version: 2
                 type: article},
  keywords    = {Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
  file        = {arXiv Fulltext PDF:/home/mjhukig/Zotero/storage/PGW8MJJ2/Wei et al. - 2019 - Federated Learning with Differential Privacy Algo.pdf:application/pdf;arXiv.org Snapshot:/home/mjhukig/Zotero/storage/VGKSEMQM/1911.html:text/html}
}
